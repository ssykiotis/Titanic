# Titanic
This repository contains my solution to Kaggle's Titanic competition. Using an ensemble of classifiers, I have been able to achieve ~89% accuracy on the training set and ~80% accuracy on the test set. These scores placed my solution in the top 8% of participants in the competition.

Repository contents:

* data: training and test data files
* Titanic.ipynb: Jupyter notebbok containing the solution

The solution is structured as follows:

1. Environment Setup
2. Understanding the data
3. Exploratory Data Analysis
4. Data Cleaning
5. Model Training


The classifiers that are used for the ensemble are: 

* Adaboost Classifier
* Gradient Boosting Classifier
* Support Vector Classifier (SVC)
* Random Forest Classifier
* XGBoost Classifier